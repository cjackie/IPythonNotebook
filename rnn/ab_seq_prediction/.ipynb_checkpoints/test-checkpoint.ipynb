{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import tensorflow as tf\n",
      "import numpy as np\n",
      "\n",
      "from ab_seq import ab_seq"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "batch_size, seq_len = 100, 10\n",
      "\n",
      "sess = tf.Session()\n",
      "ab = ab_seq(sess, batch_size=batch_size,seq_len=seq_len, verbose=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# generate data sequence of ab\n",
      "sequence = []\n",
      "for i in range(batch_size*seq_len):\n",
      "    if i % 2:\n",
      "        sequence.append('a')\n",
      "    else:\n",
      "        sequence.append('b')\n",
      "sequence = map(lambda x: ord(x), sequence)\n",
      "data, labels = np.ones((seq_len, batch_size, 1)), np.ones((batch_size, 2))\n",
      "                       \n",
      "for i in range(batch_size):\n",
      "    a_seq = map(lambda x: [x], sequence[i:i+seq_len])\n",
      "    data[:, i, :] = a_seq\n",
      "    if sequence[i+seq_len] == ord('a'):\n",
      "        labels[i, :] = [1,0]\n",
      "    elif sequence[i+seq_len] == ord('b'):\n",
      "        labels[i, :] = [0,1]\n",
      "    else:\n",
      "        raise Exception(\"d\")\n",
      "data[:,4,:], labels[4,:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "(array([[ 98.],\n",
        "       [ 97.],\n",
        "       [ 98.],\n",
        "       [ 97.],\n",
        "       [ 98.],\n",
        "       [ 97.],\n",
        "       [ 98.],\n",
        "       [ 97.],\n",
        "       [ 98.],\n",
        "       [ 97.]]),\n",
        " array([ 0.,  1.]))"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ab.train_model(data, labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(ab.predict('ababababab'),ab.predict('bababababa'), ab.predict('aaaaaaaaaa'),ab.predict('bbbbbbbbbb'),\n",
      "ab.predict('babaabab'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "(array([[ 0.9882853 ,  0.01171477]], dtype=float32),\n",
        " array([[ 0.00817664,  0.99182338]], dtype=float32),\n",
        " array([[ 0.91605991,  0.08394011]], dtype=float32),\n",
        " array([[ 0.15485914,  0.84514087]], dtype=float32),\n",
        " array([[ 0.05141351,  0.94858646]], dtype=float32))"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for c in 'ababababab':\n",
      "    print(ab.step(c))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "array([[ 0.90368229,  0.09631774]], dtype=float32)"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "seq_in = np.zeros((ab.seq_len, 1, 1))\n",
      "seq_in[:,0,0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
       ]
      }
     ],
     "prompt_number": 30
    }
   ],
   "metadata": {}
  }
 ]
}